# Example environment file for NKI-LLAMA
# Copy this to .env and update with your values

# Hugging Face Configuration
HF_TOKEN=your_huggingface_token_here
MODEL_ID=meta-llama/Meta-Llama-3-8B
MODEL_NAME=llama-3-8b

# Shared Configuration
TENSOR_PARALLEL_SIZE=8

# Inference Configuration
INFERENCE_PORT=8080
MAX_MODEL_LEN=2048
MAX_NUM_SEQS=4

# Inference Dataset Configuration
DATASET_NAME=databricks/databricks-dolly-15k

# Neuron Configuration
NEURON_RT_NUM_CORES=8

# Jupyter Configuration
JUPYTER_PORT=8888